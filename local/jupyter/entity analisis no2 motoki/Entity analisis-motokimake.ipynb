{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-crfsuite in /opt/conda/lib/python3.7/site-packages (0.9.6)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install python-crfsuite\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "import pycrfsuite\n",
    "import sklearn\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "\n",
    "class CorpusReader(object):\n",
    "\n",
    "    def __init__(self, path):\n",
    "        with codecs.open(path, encoding='utf-8') as f:\n",
    "            sent = []\n",
    "            sents = []\n",
    "            for line in f:\n",
    "                if line == '\\n':\n",
    "                    sents.append(sent)\n",
    "                    sent = []\n",
    "                    continue\n",
    "                morph_info = line.strip().split('\\t')\n",
    "                sent.append(morph_info)\n",
    "        train_num = int(len(sents) * 0.9)\n",
    "        self.__train_sents = sents[:train_num]\n",
    "        self.__test_sents = sents[train_num:]\n",
    "\n",
    "    def iob_sents(self, name):\n",
    "        if name == 'train':\n",
    "            return self.__train_sents\n",
    "        elif name == 'test':\n",
    "            return self.__test_sents\n",
    "        else:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = CorpusReader('motoki.txt')\n",
    "train_sents = c.iob_sents('train')\n",
    "test_sents = c.iob_sents('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_hiragana(ch):\n",
    "    return 0x3040 <= ord(ch) <= 0x309F\n",
    "\n",
    "def is_katakana(ch):\n",
    "    return 0x30A0 <= ord(ch) <= 0x30FF\n",
    "\n",
    "def get_character_type(ch):\n",
    "    if ch.isspace():\n",
    "        return 'ZSPACE'\n",
    "    elif ch.isdigit():\n",
    "        return 'ZDIGIT'\n",
    "    elif ch.islower():\n",
    "        return 'ZLLET'\n",
    "    elif ch.isupper():\n",
    "        return 'ZULET'\n",
    "    elif is_hiragana(ch):\n",
    "        return 'HIRAG'\n",
    "    elif is_katakana(ch):\n",
    "        return 'KATAK'\n",
    "    else:\n",
    "        return 'OTHER'\n",
    "\n",
    "def get_character_types(string):\n",
    "    character_types = map(get_character_type, string)\n",
    "    character_types_str = '-'.join(sorted(set(character_types)))\n",
    "\n",
    "    return character_types_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pos_with_subtype(morph):\n",
    "    idx = morph.index('*')\n",
    "\n",
    "    return '-'.join(morph[1:idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    chtype = get_character_types(sent[i][0])\n",
    "    postag = extract_pos_with_subtype(sent[i])\n",
    "    features = [\n",
    "        'bias',\n",
    "        'word=' + word,\n",
    "        'type=' + chtype,\n",
    "        'postag=' + postag,\n",
    "    ]\n",
    "    if i >= 2:\n",
    "        word2 = sent[i-2][0]\n",
    "        chtype2 = get_character_types(sent[i-2][0])\n",
    "        postag2 = extract_pos_with_subtype(sent[i-2])\n",
    "        iobtag2 = sent[i-2][-1]\n",
    "        features.extend([\n",
    "            '-2:word=' + word2,\n",
    "            '-2:type=' + chtype2,\n",
    "            '-2:postag=' + postag2,\n",
    "            '-2:iobtag=' + iobtag2,\n",
    "        ])\n",
    "    else:\n",
    "        features.append('BOS')\n",
    "\n",
    "    if i >= 1:\n",
    "        word1 = sent[i-1][0]\n",
    "        chtype1 = get_character_types(sent[i-1][0])\n",
    "        postag1 = extract_pos_with_subtype(sent[i-1])\n",
    "        iobtag1 = sent[i-1][-1]\n",
    "        features.extend([\n",
    "            '-1:word=' + word1,\n",
    "            '-1:type=' + chtype1,\n",
    "            '-1:postag=' + postag1,\n",
    "            '-1:iobtag=' + iobtag1,\n",
    "        ])\n",
    "    else:\n",
    "        features.append('BOS')\n",
    "\n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        chtype1 = get_character_types(sent[i+1][0])\n",
    "        postag1 = extract_pos_with_subtype(sent[i+1])\n",
    "        features.extend([\n",
    "            '+1:word=' + word1,\n",
    "            '+1:type=' + chtype1,\n",
    "            '+1:postag=' + postag1,\n",
    "        ])\n",
    "    else:\n",
    "        features.append('EOS')\n",
    "\n",
    "    if i < len(sent)-2:\n",
    "        word2 = sent[i+2][0]\n",
    "        chtype2 = get_character_types(sent[i+2][0])\n",
    "        postag2 = extract_pos_with_subtype(sent[i+2])\n",
    "        features.extend([\n",
    "            '+2:word=' + word2,\n",
    "            '+2:type=' + chtype2,\n",
    "            '+2:postag=' + postag2,\n",
    "        ])\n",
    "    else:\n",
    "        features.append('EOS')\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [morph[-1] for morph in sent]\n",
    "\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [morph[0] for morph in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bias',\n",
       " 'word=芥川賞',\n",
       " 'type=OTHER',\n",
       " 'postag=名詞-固有名詞-一般',\n",
       " 'BOS',\n",
       " 'BOS',\n",
       " '+1:word=は',\n",
       " '+1:type=HIRAG',\n",
       " '+1:postag=助詞-係助詞',\n",
       " '+2:word=「',\n",
       " '+2:type=OTHER',\n",
       " '+2:postag=記号-括弧開']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent2features(train_sents[0])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [sent2features(s) for s in train_sents]\n",
    "y_train = [sent2labels(s) for s in train_sents]\n",
    "\n",
    "X_test = [sent2features(s) for s in test_sents]\n",
    "y_test = [sent2labels(s) for s in test_sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pycrfsuite.Trainer(verbose=False)\n",
    "\n",
    "for xseq, yseq in zip(X_train, y_train):\n",
    "    trainer.append(xseq, yseq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train('model.crfsuite')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.closing at 0x7fa86a5889d0>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger = pycrfsuite.Tagger()\n",
    "tagger.open('model.crfsuite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "震源 は 千葉 県 北西 部 、 震源 の 深 さ は 約 73 km 、 地震 の 規模 を 示す マグニチュード は 6 . 0 と 推定 し て いる 。\n",
      "Predicted: O O B-LOC I-LOC O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "Correct:   O O B-LOC I-LOC O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n"
     ]
    }
   ],
   "source": [
    "example_sent = test_sents[10]\n",
    "print(' '.join(sent2tokens(example_sent)))\n",
    "\n",
    "print(\"Predicted:\", ' '.join(tagger.tag(sent2features(example_sent))))\n",
    "print(\"Correct:  \", ' '.join(sent2labels(example_sent)))\n",
    "\n",
    "\n",
    "x = sent2labels(example_sent)\n",
    "\n",
    "for i in range(len(x)):\n",
    "    if x[i]== 'B-PSN':\n",
    "        s = sent2tokens(example_sent)\n",
    "        print('名前：'+s[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "入力データ： 地元 の LBC テレビ は 当初 、 主 に 飛散 し た ガラス の 破片 により 6 名 が 負傷 し 、 乗用車 の 所有 者 は 地元 の 住民 元木大介 た と 報じ た 。\n",
      "名前：元木大介(正解データ)\n",
      "名前：O(予測値)\n"
     ]
    }
   ],
   "source": [
    "example_sent = test_sents[44]\n",
    "print('入力データ： ' + ' '.join(sent2tokens(example_sent)))\n",
    "\n",
    "x = sent2labels(example_sent)\n",
    "\n",
    "for i in range(len(x)):\n",
    "    if x[i]== 'B-PSN':\n",
    "        s = sent2tokens(example_sent)\n",
    "        print('名前：'+s[i]+ '(正解データ)')                \n",
    "\n",
    "for i in range(len(x)):\n",
    "    if x[i]== 'B-PSN':\n",
    "        s = tagger.tag(sent2features(example_sent))\n",
    "        print('名前：'+s[i]+ '(予測値)')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BBC の 報道 に よれ ば 、 少なくとも 49 人 が 死亡 し た 。\n",
      "Predicted: B-ORG O O O O O O O O O O O O O O\n",
      "Correct:   B-ORG O O O O O O O O O O O O O O\n",
      "ロイター通信 社 報道局 は 、 現場 に い た 複数 の 医師 が 、 負傷 者 の 多く は 危険 な 状態 に ある と 語っ て いる と 伝え た 。\n",
      "Predicted: B-ORG I-ORG I-ORG O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "Correct:   B-ORG I-ORG I-ORG O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "また ロイター で は 爆弾 は おそらく 車 に 仕掛け られ て い た と 報じ た 。\n",
      "Predicted: O B-ORG O O O O O O O O O O O O O O O O\n",
      "Correct:   O B-ORG O O O O O O O O O O O O O O O O\n",
      "死亡 者 の 中 に は 、 イギリス 人 、 フランス 人 、 スペイン 人 、 オランダ 人 、 カタール 人 、 クウェート 人 、 エジプト 人 が 含ま れ て いる と AP 通信 が 伝え て いる 。\n",
      "Predicted: O O O O O O O B-LOC O O B-LOC O O B-LOC O O B-LOC O O B-LOC O O B-LOC O O B-LOC O O O O O O O O O O O O O O\n",
      "Correct:   O O O O O O O B-LOC O O B-LOC O O B-LOC O O B-LOC O O B-LOC O O B-LOC O O B-LOC O O O O O O O B-ORG I-ORG O O O O O\n",
      "アメリカ の マイクロソフト は 現地 時間 2005 年 7 月 22 日 、 同社 の オペレーティングシステム （ OS ） 、 Windows XP の 次に リリース さ れる OS の 正式 名称 を 「 Windows Vista 」 （ ウィンドウズ ・ ビスタ ） に する と 発表 し た 。\n",
      "Predicted: B-LOC O B-ORG O O O B-DAT I-DAT I-DAT I-DAT I-DAT I-DAT O O O O O B-ORG O O B-ART I-ART O O O O O O O O O O O B-ART I-ART O O B-ART I-ART I-ART O O O O O O O O\n",
      "Correct:   B-LOC O B-ORG O O O B-DAT I-DAT I-DAT I-DAT I-DAT I-DAT O O O O O O O O B-ART I-ART O O O O O O O O O O O B-ART I-ART O O B-ART I-ART I-ART O O O O O O O O\n",
      "それ と 同時に 、 Windows Vista の 公式 サイト が 開設 さ れ 、 追って 日本語 版 の サイト も 開設 さ れ た 。\n",
      "Predicted: O O O O B-ART I-ART O O O O O O O O O O O O O O O O O O O\n",
      "Correct:   O O O O B-ART I-ART O O O O O O O O O O O O O O O O O O O\n",
      "Vista と は 、 展望 、 眺望 、 見通し 、 予想 、 美しい 景色 など を 意味 する 単語 で ある 。\n",
      "Predicted: B-ORG O O O O O O O O O O O O O O O O O O O O O\n",
      "Correct:   O O O O O O O O O O O O O O O O O O O O O O\n",
      "同 OS の 開発 コードネーム は 「 Longhorn 」 （ ロング ホーン ） で 、 正式 名称 が 発表 さ れる まで は その コードネーム で 呼ば れ て い た 。\n",
      "Predicted: O O O O O O O B-ART O O B-ART I-ART O O O O O O O O O O O O O O O O O O O O\n",
      "Correct:   O O O O O O O B-ART O O B-ART I-ART O O O O O O O O O O O O O O O O O O O O\n",
      "同社 は 、 開発 者 や 技術 者 向け の ベータ 版 を 2005 年 8 月 3 日 （ 日本 時間 : 8 月 4 日 ） 頃 に リリース する 予定 と 発表 し て いる 。\n",
      "Predicted: O O O O O O O O O O O O O B-DAT I-DAT I-DAT I-DAT I-DAT I-DAT O B-LOC O O B-DAT I-DAT I-DAT I-DAT O O O O O O O O O O O O\n",
      "Correct:   O O O O O O O O O O O O O B-DAT I-DAT I-DAT I-DAT I-DAT I-DAT O B-LOC O O B-DAT I-DAT I-DAT I-DAT O O O O O O O O O O O O\n",
      "気象庁 に よる と 、 23 日 午後 4 時 35 分 （ 以下 本文 は すべて 日本 時間 、 UTC + 9 ) ごろ 、 関東 地方 ・ 甲信越 など 広い 地域 で 最大 震度 5 強 の 地震 が あっ た 。\n",
      "Predicted: B-ORG O O O O B-DAT I-DAT B-TIM I-TIM I-TIM I-TIM I-TIM O O O O O B-LOC O O B-ORG O O O O O B-LOC O O B-LOC O O O O O O O O O O O O O O\n",
      "Correct:   B-ORG O O O O B-DAT I-DAT B-TIM I-TIM I-TIM I-TIM I-TIM O O O O O B-LOC O O O O O O O O B-LOC O O B-LOC O O O O O O O O O O O O O O\n",
      "震源 は 千葉 県 北西 部 、 震源 の 深 さ は 約 73 km 、 地震 の 規模 を 示す マグニチュード は 6 . 0 と 推定 し て いる 。\n",
      "Predicted: O O B-LOC I-LOC O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "Correct:   O O B-LOC I-LOC O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "この 地震 による 津波 の 心配 は ない 。\n",
      "Predicted: O O O O O O O O O\n",
      "Correct:   O O O O O O O O O\n",
      "気象庁 が 発表 し た 各地 の 主 な 震度 は 次 の とおり 。\n",
      "Predicted: B-ORG O O O O O O O O O O O O O O\n",
      "Correct:   B-ORG O O O O O O O O O O O O O O\n",
      "Yahoo ! 路線 情報 等 による 、 記事 発行 時 （ 23 時 ） の 状況 は 次 の 通り 。\n",
      "Predicted: B-ART I-ART I-ART I-ART I-ART O O O O O O O O O O O O O O O O\n",
      "Correct:   B-ART I-ART I-ART I-ART O O O O O O O O O O O O O O O O O\n",
      "東京 ・ 埼玉 ・ 千葉 ・ 神奈川 で 2 時間 あまり 通話 が 規制 さ れ た 。\n",
      "Predicted: B-LOC O B-LOC O B-LOC O B-LOC O O O O O O O O O O O\n",
      "Correct:   B-LOC O B-LOC O B-LOC O B-LOC O O O O O O O O O O O\n",
      "エレベーター の 中 に 人 が 閉じ込め られる 被害 が 4 都県 で 46 件 。\n",
      "Predicted: O O O O O O O O O O O O O O O O\n",
      "Correct:   O O O O O O O O O O O O O O O O\n",
      "すべて 救出 済み 。\n",
      "Predicted: O O O O\n",
      "Correct:   O O O O\n",
      "（ 22 時 現在 ）\n",
      "Predicted: O O O O O\n",
      "Correct:   O B-TIM I-TIM O O\n",
      "三郷 市 の カラオケ 店 で は 、 ガラス の 破片 が 刺さり 女性 が けが を し た と の 情報 。\n",
      "Predicted: B-LOC I-LOC O O O O O O O O O O O O O O O O O O O O O\n",
      "Correct:   B-LOC I-LOC O O O O O O O O O O O O O O O O O O O O O\n",
      "鴻巣 市 の ホームセンター で は 落ち た 案内 板 で 客 5 人 が 軽傷 を 負っ た 。\n",
      "Predicted: B-LOC I-LOC O O O O O O O O O O O O O O O O O O\n",
      "Correct:   B-LOC I-LOC O O O O O O O O O O O O O O O O O O\n",
      "新宿 区 ・ 品川 区 ・ 足立 区 ・ 豊島 区 で は 、 6 箇所 で エレベーター が 停止 し 人 が 閉じ込め られ て いる と の 情報 。\n",
      "Predicted: B-LOC I-LOC O B-LOC I-LOC O B-LOC I-LOC O B-LOC I-LOC O O O O O O O O O O O O O O O O O O O O\n",
      "Correct:   B-LOC I-LOC O B-LOC I-LOC O B-LOC I-LOC O B-LOC I-LOC O O O O O O O O O O O O O O O O O O O O\n",
      "足立 区 で は 熱湯 が かかり やけど を し た という 通報 が あっ た と の 情報 。\n",
      "Predicted: B-LOC I-LOC O O O O O O O O O O O O O O O O O O\n",
      "Correct:   B-LOC I-LOC O O O O O O O O O O O O O O O O O O\n",
      "目黒 区 の 民家 で は 火災 が 発生 。\n",
      "Predicted: B-LOC I-LOC O O O O O O O O\n",
      "Correct:   B-LOC I-LOC O O O O O O O O\n",
      "けが人 なし 。\n",
      "Predicted: O O O\n",
      "Correct:   O O O\n",
      "江戸川 区 で は 鉄塔 が 倒れ 高圧線 が 落下 。\n",
      "Predicted: B-LOC I-LOC O O O O O O O O O\n",
      "Correct:   B-LOC I-LOC O O O O O O O O O\n",
      "隣家 の 屋根 など が 焦げ た が けが人 は なし 。\n",
      "Predicted: O O O O O O O O O O O O\n",
      "Correct:   O O O O O O O O O O O O\n",
      "江東 区 の 立体 駐車 場 で 2 階 から 乗用車 が 地上 に 落ち た 。\n",
      "Predicted: B-LOC I-LOC O O O O O O O O O O O O O O O\n",
      "Correct:   B-LOC I-LOC O O O O O O O O O O O O O O O\n",
      "けが人 なし 。\n",
      "Predicted: O O O\n",
      "Correct:   O O O\n",
      "毎日新聞 に よる と 、 23 日 21 時 2 分 現在 で 、 東京 ・ 埼玉 ・ 千葉 ・ 神奈川 の 4 都県 で 計 29 人 が 重軽傷 を 負っ た 。\n",
      "Predicted: B-ORG O O O O B-DAT I-DAT B-TIM I-TIM I-TIM I-TIM O O O B-LOC O B-LOC O B-LOC O B-LOC O O O O O O O O O O O O O\n",
      "Correct:   B-ORG O O O O B-DAT I-DAT B-TIM I-TIM I-TIM I-TIM O O O B-LOC O B-LOC O B-LOC O B-LOC O O O O O O O O O O O O O\n",
      "22 日 英語 版 ウィキニュース に よる と 、\n",
      "Predicted: B-DAT I-DAT O O O O O O O\n",
      "Correct:   B-DAT I-DAT O O B-ORG O O O O\n",
      "イギリス の ロンドン 首都 警察 は 南 ロンドン の ストックウェル に ある 住宅 で 容疑 者 を 逮捕 しよ う と し た と 発表 し 、 「 これ は 21 日 の 爆破 事件 の 捜査 の 一環 で ある 」 と 語っ た 。\n",
      "Predicted: B-LOC O B-LOC O O O O B-LOC O O O O O O O O O O O O O O O O O O O O O O B-DAT I-DAT O O O O O O O O O O O O O O\n",
      "Correct:   B-LOC O B-LOC O O O B-LOC I-LOC O B-LOC O O O O O O O O O O O O O O O O O O O O B-DAT I-DAT O O O O O O O O O O O O O O\n",
      "爆発 現場 付近 で 監視 カメラ 網 （ CCTV ) の カメラ が 捉え た 男性 の 写真 4 枚 と 、 この 容疑 者 が 同 一人物 か どう か について は 、 当局 は コメント し ない 意向 で ある 。\n",
      "Predicted: O O O O O O O O B-ORG O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "Correct:   O O O O O O O O B-ART O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "また 同日 現地 時間 午後 6 時 すぎ 、 バーミンガム 市 中心 部 の 鉄道 駅 スノウ・ヒル 駅 で テロ 法 44 項 により 警察 が 男性 1 名 を 逮捕 し た 。\n",
      "Predicted: O O O O B-TIM I-TIM I-TIM O O B-LOC I-LOC O O O O O B-LOC I-LOC O O O O O O O O O O O O O O O O\n",
      "Correct:   O O O O B-TIM I-TIM I-TIM O O B-LOC I-LOC O O O O O B-LOC I-LOC O B-ART I-ART I-ART I-ART O O O O O O O O O O O\n",
      "駅 構内 で 2 個 の 疑わしい スーツケース が 発見 さ れ た ため 、 駅 は 非常 線 が 張ら れ 人 は 退避 さ せ られ て い た 。\n",
      "Predicted: O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "Correct:   O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "スーツケース は 調査 さ れ 、 爆発 物 は 入っ て い なかっ た こと が 判明 し た 。\n",
      "Predicted: O O O O O O O O O O O O O O O O O O O O\n",
      "Correct:   O O O O O O O O O O O O O O O O O O O O\n",
      "逮捕 さ れ た 男性 は 不 起訴 に なる だろ う と BBC は 報道 し た 。\n",
      "Predicted: O O O O O O O O O O O O O O O O O O O\n",
      "Correct:   O O O O O O O O O O O O O B-ORG O O O O O\n",
      "スノウ・ヒル 駅 は 現時 時間 午後 8 時 に 再び 開放 さ れ た 。\n",
      "Predicted: B-LOC I-LOC O O O B-TIM I-TIM I-TIM O O O O O O O\n",
      "Correct:   B-LOC I-LOC O O O B-TIM I-TIM I-TIM O O O O O O O\n",
      "レバノン の 位置\n",
      "Predicted: B-LOC O O\n",
      "Correct:   B-LOC O O\n",
      "23 日 、 レバノン の 首都 ベイルート の レストラン 街 で 爆発 が あり 、 少なくとも 12 人 が 負傷 し た 。\n",
      "Predicted: B-DAT I-DAT O B-LOC O O B-LOC O O O O O O O O O O O O O O O O\n",
      "Correct:   B-DAT I-DAT O B-LOC O O B-LOC O O O O O O O O O O O O O O O O\n",
      "22 日 より ベイ ルート を 訪問 し て い た ライス 米 国務 長官 が 出国 し て から 2 時間 後 だっ た 。\n",
      "Predicted: B-DAT I-DAT O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "Correct:   B-DAT I-DAT O B-LOC I-LOC O O O O O O B-PSN B-LOC O O O O O O O B-TIM I-TIM I-TIM O O O\n",
      "22 日 、 イスラエル より 専用 機 で レバノン 入り し た ライス 長官 の 電撃 訪問 は 、 今年 始まっ た シリア の レバノン 撤兵 と レバノン 新 政権 へ の 支援 を 確実 な もの に する 目的 で 行わ れ た 。\n",
      "Predicted: B-DAT I-DAT O B-LOC O O O O O O O O O O O O O O O O O O B-LOC O B-LOC O O B-LOC O O O O O O O O O O O O O O O O O\n",
      "Correct:   B-DAT I-DAT O B-LOC O O O O B-LOC O O O B-PSN O O O O O O B-DAT O O B-LOC O B-LOC O O B-LOC O O O O O O O O O O O O O O O O O\n",
      "爆発 は 午後 10 時 頃 レストラン の 前 で 起こり 、 3 台 の 乗用車 を 破壊 し た 、 と 治安 当局 者 は AP 通信 に 語っ た 。\n",
      "Predicted: O O B-TIM I-TIM I-TIM O O O O O O O O O O O O O O O O O O O O O B-ORG O O O O O\n",
      "Correct:   O O B-TIM I-TIM I-TIM O O O O O O O O O O O O O O O O O O O O O B-ORG I-ORG O O O O\n",
      "爆弾 は 路上 に 駐車 し た 乗用車 の 下 または 中 に 仕掛け られ た と 推測 さ れ て いる 。\n",
      "Predicted: O O O O O O O O O O O O O O O O O O O O O O O\n",
      "Correct:   O O O O O O O O O O O O O O O O O O O O O O O\n",
      "場所 は 、 東 ベイルート の キリスト教徒 居住 地区 の 境界 部 にあたる 私立 ・ 聖 ヨハネ 大学 の 付近 で ある 。\n",
      "Predicted: O O O O B-LOC O O O O O O O O B-ORG I-ORG I-ORG I-ORG I-ORG O O O O O\n",
      "Correct:   O O O B-LOC I-LOC O O O O O O O O B-ORG I-ORG I-ORG I-ORG I-ORG O O O O O\n",
      "地元 の LBC テレビ は 当初 、 主 に 飛散 し た ガラス の 破片 により 6 名 が 負傷 し 、 乗用車 の 所有 者 は 地元 の 住民 元木大介 た と 報じ た 。\n",
      "Predicted: O O B-ORG I-ORG O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "Correct:   O O B-ORG I-ORG O O O O O O O O O O O O O O O O O O O O O O O O O O B-PSN O O O O O\n",
      "LBC テレビ により 報道 さ れ た 負傷 者 の 数 は その後 増え 、 少なくとも 12 名 が 負傷 し た と 報道 さ れ た 。\n",
      "Predicted: B-ORG I-ORG O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "Correct:   B-ORG I-ORG O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "地元 の LBC テレビ は 当初 、 主 に 飛散 し た ガラス の 破片 により 6 名 が 負傷 し 、 乗用車 の 所有 者 は 地元 の 住民 元木大介 た と 報じ た 。\n",
      "Predicted: O O B-ORG I-ORG O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "Correct:   O O B-ORG I-ORG O O O O O O O O O O O O O O O O O O O O O O O O O O B-PSN O O O O O\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-3cc751b433d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mexample_sent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_sents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent2tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample_sent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Predicted:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtagger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent2features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample_sent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    example_sent = test_sents[i]\n",
    "    print(' '.join(sent2tokens(example_sent)))\n",
    "\n",
    "    print(\"Predicted:\", ' '.join(tagger.tag(sent2features(example_sent))))\n",
    "    print(\"Correct:  \", ' '.join(sent2labels(example_sent)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_sent = test_sents[0]\n",
    "print(' '.join(sent2tokens(example_sent)))\n",
    "\n",
    "print(\"Predicted:\", ' '.join(tagger.tag(sent2features(example_sent))))\n",
    "print(\"Correct:  \", ' '.join(sent2labels(example_sent)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 履歴書 データ前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "履歴\t名詞,一般,*,*,*,*,履歴,リレキ,リレキ\n",
      "書\t名詞,接尾,一般,*,*,*,書,ショ,ショ\n",
      "ふりがな\t名詞,一般,*,*,*,*,ふりがな,フリガナ,フリガナ\n",
      "さとう\t形容詞,自立,*,*,形容詞・アウオ段,連用ゴザイ接続,さとい,サトウ,サトー\n",
      "いちろう\t名詞,固有名詞,人名,名,*,*,いちろう,イチロウ,イチロー\n",
      "名前\t名詞,一般,*,*,*,*,名前,ナマエ,ナマエ\n",
      "砂糖\t名詞,一般,*,*,*,*,砂糖,サトウ,サトー\n",
      "一\t名詞,数,*,*,*,*,一,イチ,イチ\n",
      "郎\t名詞,一般,*,*,*,*,郎,ロウ,ロー\n",
      "2019\t名詞,数,*,*,*,*,*\n",
      "年\t名詞,接尾,助数詞,*,*,*,年,ネン,ネン\n",
      "12\t名詞,数,*,*,*,*,*\n",
      "月\t名詞,一般,*,*,*,*,月,ツキ,ツキ\n",
      "25\t名詞,数,*,*,*,*,*\n",
      "日\t名詞,接尾,助数詞,*,*,*,日,ニチ,ニチ\n",
      "EOS\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import MeCab\n",
    "mytext = '履歴書ふりがなさとういちろう名前砂糖一郎2019年12月25日'\n",
    "tagger = MeCab.Tagger()\n",
    "print(tagger.parse(mytext))\n",
    "\n",
    "t = tagger.parse(mytext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'履歴\\t名詞\\t一般\\t*\\t*\\t*\\t*\\t履歴\\tリレキ\\tリレキ\\n書\\t名詞\\t接尾\\t一般\\t*\\t*\\t*\\t書\\tショ\\tショ\\nふりがな\\t名詞\\t一般\\t*\\t*\\t*\\t*\\tふりがな\\tフリガナ\\tフリガナ\\nさとう\\t形容詞\\t自立\\t*\\t*\\t形容詞・アウオ段\\t連用ゴザイ接続\\tさとい\\tサトウ\\tサトー\\nいちろう\\t名詞\\t固有名詞\\t人名\\t名\\t*\\t*\\tいちろう\\tイチロウ\\tイチロー\\n名前\\t名詞\\t一般\\t*\\t*\\t*\\t*\\t名前\\tナマエ\\tナマエ\\n砂糖\\t名詞\\t一般\\t*\\t*\\t*\\t*\\t砂糖\\tサトウ\\tサトー\\n一\\t名詞\\t数\\t*\\t*\\t*\\t*\\t一\\tイチ\\tイチ\\n郎\\t名詞\\t一般\\t*\\t*\\t*\\t*\\t郎\\tロウ\\tロー\\n2019\\t名詞\\t数\\t*\\t*\\t*\\t*\\t*\\n年\\t名詞\\t接尾\\t助数詞\\t*\\t*\\t*\\t年\\tネン\\tネン\\n12\\t名詞\\t数\\t*\\t*\\t*\\t*\\t*\\n月\\t名詞\\t一般\\t*\\t*\\t*\\t*\\t月\\tツキ\\tツキ\\n25\\t名詞\\t数\\t*\\t*\\t*\\t*\\t*\\n日\\t名詞\\t接尾\\t助数詞\\t*\\t*\\t*\\t日\\tニチ\\tニチ\\nEOS\\n'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = '\t'.join(t.split(\",\"))\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f = open('text.txt', 'w') # 書き込みモードで開く\n",
    "f.write(text) # 引数の文字列をファイルに書き込む\n",
    "f.close() # ファイルを閉じる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
